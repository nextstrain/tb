"""
Fetch metadata from NCBI SRA, filter and subsample, fetch fastq files, run snippy & tbprofiler

"""
# The workflow filepaths are written relative to this Snakefile's base directory
workdir: workflow.current_basedir

configfile: "defaults/config.yaml"

rule all:
    input:
        metadata_stats="data/metadata_stats.tsv"

rule download:
    """Downloading metadata from data.nextstrain.org"""
    # FIXME: query from AWS-hosted SRA metadata
    output:
        metadata_raw = "data/metadata_raw.tsv"
    params:
        metadata_url = "https://data.nextstrain.org/files/workflows/tb/tb_metadata_illumina_20250211.tsv"
    shell:
        """
        curl -fsSL {params.metadata_url:q} --output {output.metadata_raw:q}
        """

def format_field_map(field_map: dict[str, str]) -> str:
    """
    Format dict to `"key1"="value1" "key2"="value2"...` for use in shell commands.
    """
    return " ".join([f'"{key}"="{value}"' for key, value in field_map.items()])

rule curate:
    input:
        metadata_raw = "data/metadata_raw.tsv",
        annotations = config["curate"]["annotations"],
    output:
        metadata_curate = "data/metadata_curate.tsv"
    log:
        "logs/curate.txt"
    benchmark:
        "benchmarks/curate.txt"
    params:
        field_map = format_field_map(config["curate"]["field_map"]),
        strain_regex = config["curate"]["strain_regex"],
        strain_backup_fields = config["curate"]["strain_backup_fields"],
        date_fields = config["curate"]["date_fields"],
        expected_date_formats = config["curate"]["expected_date_formats"],
        articles = config["curate"]["titlecase"]["articles"],
        abbreviations = config["curate"]["titlecase"]["abbreviations"],
        titlecase_fields = config["curate"]["titlecase"]["fields"],
        annotations_id = config["curate"]["annotations_id"],
        id_field = config["curate"]["output_id_field"],
    shell:
        """
        augur curate passthru \
            --metadata {input.metadata_raw} \
            | augur curate rename \
                --field-map {params.field_map} \
            | augur curate normalize-strings \
            | augur curate transform-strain-name \
                --strain-regex {params.strain_regex} \
                --backup-fields {params.strain_backup_fields} \
            | augur curate format-dates \
                --date-fields {params.date_fields} \
                --expected-date-formats {params.expected_date_formats} \
                --failure-reporting silent \
            | augur curate titlecase \
                --titlecase-fields {params.titlecase_fields} \
                --articles {params.articles} \
                --abbreviations {params.abbreviations} \
            | augur curate apply-record-annotations \
                --annotations {input.annotations} \
                --id-field {params.annotations_id} \
                --output-metadata {output.metadata_curate} 2>> {log}
        """

rule filter_subsample:
    input:
        metadata_curate = "data/metadata_curate.tsv"
    output:
        metadata_subsample = "data/metadata_subsample.tsv"
    log:
        "logs/filter_subsample.txt"
    benchmark:
        "benchmarks/filter_subsample.txt"
    shell:
        # temporarily including a single SRA accession for testing purposes
        # FIXME: use commented version below
        r"""
        augur filter \
            --metadata {input.metadata_curate:q} \
            --exclude-all \
            --include-where accession=SRR19320509 \
            --output-metadata {output.metadata_subsample} \
        2>&1 | tee {log}
        """
        # FIXME: make some options configurable
        # r"""
        # augur filter \
        #     --metadata {input.metadata_curate:q} \
        #     --metadata-id-columns accession \
        #     --query "(mbases > 180 & (country != 'Uncalculated'))" \
	    #     --group-by country year \
	    #     --sequences-per-group 1 \
	    #     --min-date 2022 \
	    #     --output-metadata {output.metadata_subsample} \
        # 2>&1 | tee {log}
        # """

rule process_sequences:
    input:
        metadata_subsample = "data/metadata_subsample.tsv"
    output:
        tbprofiler_summary = "data/tbprofiler_summary.txt",
        snippy_summary = "data/snippy_summary.tsv",
    shell:
        r"""
        ./scripts/process-sequences {input.metadata_subsample:q} {output.tbprofiler_summary:q} {output.snippy_summary:q}
        """


rule merge_metadata:
    # NOTE: tbprofiler output has Windows line endings, which tsv-utils cannot handle, but augur merge can.
    input:
        metadata_curate="data/metadata_curate.tsv",
        tbprofiler_summary = "data/tbprofiler_summary.txt",
        snippy_summary = "data/snippy_summary.tsv",
    output:
        metadata_stats="data/metadata_stats.tsv"
    benchmark:
        "benchmarks/merge_metadata.txt"
    shell:
        """
        augur merge \
            --metadata ncbi={input.metadata_curate:q} \
                tbprofiler={input.tbprofiler_summary:q} \
                snippy={input.snippy_summary:q} \
            --metadata-id-columns \
                accession \
                sample \
                ID \
            --output-metadata {output.metadata_stats:q}
        """

rule filter_qc:
    """
    Filter out poor-quality samples and samples that are M. canetti.
    Filter out samples with main_lineage:';' which indicates unclear 
    lineage assignments by tb-profiler.
    """
    # FIXME: filter out samples that failed to process
    input:
        metadata_stats="data/metadata_stats.tsv"
    output:
        metadata="results/metadata.tsv"
    log:
        "logs/filter_qc.txt"
    benchmark:
        "benchmarks/filter_qc.txt"
    shell:
        """
        tsv-filter --header --gt  pct_reads_mapped:80 {input.metadata_stats:q} \
        | tsv-filter --header --gt  target_median_depth:30 \
        | tsv-filter --header --gt  ALIGNED:3529226 \
        | tsv-filter --header --str-eq main_lineage:M.canetti  --invert \
        | tsv-filter --header --regex main_lineage:';' --invert \
        > {output.metadata:q}
        """
