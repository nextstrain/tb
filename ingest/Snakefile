"""
Fetch fastq sequence data from NCBI SRA, run snippy & tbprofiler

Required input = defaults/samplelist.tsv, defaults/metadata.tsv

"""
# The workflow filepaths are written relative to this Snakefile's base directory
workdir: workflow.current_basedir

# Use default configuration values. Override with Snakemake's --configfile/--config options.
# configfile: "defaults/config.yaml"

with open("defaults/samplelist.tsv", "r", encoding="utf-8") as samplelist:
    samplenames = [line.strip() for line in list(samplelist)[1:]]

# All samples (paired end and single end) should have a *_1.fastq.gz file
# Paired end samples should also have a *_2.fastq.gz file
rule all:
    input:
        expand("data/fastq/{sample}_1.fastq.gz", sample=samplenames),
        expand("data/tbprofiler/results/{sample}.results.txt", sample=samplenames),
        metadata="results/metadata.tsv",
        clean_alignment="results/clean.full.aln",
        vcf="results/all.vcf.gz"

rule fetch_fastq:
    output:
        "data/fastq/{sample}_1.fastq.gz",
    params:
        outdir="data/fastq"
    benchmark:
        "benchmarks/fetch_fastq_{sample}.txt"
    conda:
        "envs/sra-tools.yaml"
    shell:
        """
        fastq-dump --split-files \
        --gzip {wildcards.sample} \
        --outdir {params.outdir}
        """

# This analysis uses the default reference database provided by tb-profiler.
# The 'tb-profiler update_tbdb' command restores the original tb-profiler
# database and is only needed if you have previously run tb-profiler using
# a custom reference database.
# The syntax for tb-profiler commands is different for samples that 
# have paired end (PE) vs. single end (SE) reads.
rule tbprofiler:
    input:
        read1="data/fastq/{sample}_1.fastq.gz"
    output:
        "data/tbprofiler/results/{sample}.results.txt"
    params:
        outdir="data/tbprofiler"
    log:
        "logs/tbprofiler_{sample}.txt",
    benchmark:
        "benchmarks/tbprofiler_{sample}.txt"
    conda:
        "envs/tb-profiler.yaml"
    shell:
        """
        tb-profiler update_tbdb
        tb-profiler profile \
        $(if [ -f data/fastq/{wildcards.sample}_2.fastq.gz ]; then \
            echo "-1 {input.read1} \
            -2 data/fastq/{wildcards.sample}_2.fastq.gz"; \
        else \
            echo "-1 {input.read1}"; \
        fi) \
        -p {wildcards.sample} --txt --dir {params.outdir}
        """

rule tbprofiler_collate:
    input:
       expand("data/tbprofiler/results/{sample}.results.txt", sample=samplenames)
    output:
        "data/tbprofiler/results/tbprofiler_all.txt"
    params:
        prefix="data/tbprofiler/results/tbprofiler_all",
        outdir="data/tbprofiler/results"
    benchmark:
        "benchmarks/tbprofiler_collate.txt"
    conda:
        "envs/tb-profiler.yaml"
    shell:
        """
        tb-profiler collate \
        --prefix {params.prefix} \
        --dir {params.outdir}
        """

rule merge_tbprofiler_metadata:
    input:
        metadata_curate="defaults/metadata.tsv",
        tbprofiler_output="data/tbprofiler/results/tbprofiler_all.txt"
    output:
        metadata="results/metadata.tsv",
    benchmark:
        "benchmarks/curate_metadata.txt"
    conda:
        "envs/nextstrain.yaml"
    shell:
        """
        augur merge \
        --metadata bvbrc={input.metadata_curate} \
        tbprofiler={input.tbprofiler_output} \
        --metadata-id-columns 'accession_sra' 'sample' \
        --output-metadata {output.metadata}
        """

# Snippy requires the reference genome to be a gbff file.
# The syntax for snippy commands is different for samples that 
# have paired end (PE) vs. single end (SE) reads.
rule snippy:
    input:
        read1="data/fastq/{sample}_1.fastq.gz"
    output:
        sample_outdir=directory("data/snippy/{sample}"),
        vcf="data/snippy/{sample}/snps.vcf.gz",
        consensus="data/snippy/{sample}/snps.consensus.fa",
        bam="data/snippy/{sample}/snps.bam"
    params:
        ref="defaults/GCF_000195955.2_ASM19595v2_genomic.gbff"
    benchmark:
        "benchmarks/snippy_{sample}.txt"
    conda:
        "envs/snippy.yaml"
    shell:
        """
        snippy --outdir {output.sample_outdir}  \
        $(if [ -f data/fastq/{wildcards.sample}_2.fastq.gz ]; then \
            echo "--R1 {input.read1} \
            --R2 data/fastq/{wildcards.sample}_2.fastq.gz"; \
        else \
            echo "--se {input.read1}"; \
        fi) \
        --ref {params.ref} \
        --force
        """

# Note that we had to manually change the chromosome name in the reference 
# genome from "NC_000962.3" to "NC_000962" because that is the chromosome 
# name in the gbff file that snippy used for alignment.
rule combine_align:
    input:
        samples=expand("data/snippy/{sample}", sample=samplenames),
    output:
        alignment="data/snippy/core.full.aln",
    params:
        ref="defaults/GCF_000195955.2_ASM19595v2_genomic.fna",
        prefix="data/snippy/core"
    benchmark:
        "benchmarks/snippy_combine_align.txt"
    conda:
        "envs/snippy.yaml"
    shell:
        """
        snippy-core --ref {params.ref} \
        {input.samples} \
        --prefix {params.prefix}
        """

rule clean_align:
    input:
        alignment="data/snippy/core.full.aln"
    output:
        clean_alignment="results/clean.full.aln",
    benchmark:
        "benchmarks/snippy_clean_align.txt"
    conda:
        "envs/snippy.yaml"
    shell:
        """
        snippy-clean_full_aln \
        {input.alignment} \
        > {output.clean_alignment}
        """

rule combine_vcfs:
    input:
        samples=expand("data/snippy/{sample}/snps.vcf.gz", sample=samplenames),
    output:
        vcf="results/all.vcf.gz"
    benchmark:
        "benchmarks/snippy_combine_align.txt"
    conda:
        "envs/bcftools.yaml"
    shell:
        """
        bcftools merge {input.samples} \
        -Oz -o {output.vcf} \
        --missing-to-ref
        """
